\documentclass[a4paper,english]{report}
\usepackage[utf8]{inputenc}
\usepackage{babel,duomasterforside}

\title{Masteroppgaven min}
\subtitle{Et resultat av to års arbeid}
\author{Roger Bløtekjær}

\begin{document}
	\duoforside[dept={Institutt for informatikk},
	program={Informatikk: språkteknologi},
	short]
	\section{Summary}
	\section{Foreword}
	I got nothing.
	\tableofcontents
	\chapter{Introduction/Background ?}
		\section{Target group}
		This thesis covers the deep technical aspects of big data analysis and genetic algorithms. All techniques used will be explained in detail, but it is advised to have a certain degree of technical insight before reading.
		\section{Area of research}
		Hadoop and MapReduce are already well established technologies employed in countless applications around the world. I propose a new method of implementing Hadoop clusters, with an out-of-the-box approach, meaning that this thesis purely covers the implementation aspect.
		\section{Personal motivation}
		The subject for this master thesis is a natural continuation of my previous work \emph{Hadoop MapReduce Scheduling Paradigms}, published in 2017, in the 2nd IEEE International Conference on Cloud Computing and Big Data Analysis (ISSSBDA 2017). Back then the topic was haphazardly picked from a list of eligible ones, but the more I read into it - the more I understood the incredible use cases for Hadoop within the massive industries that are driving forces for our technological advancements. It felt like an awakening when I realized the potential implications of future IoT, advanced data analysis and business intelligence.
		\section{Research method in brief}
		Throughout this thesis I will develop an entire suite of tools centered around a genetic algorithm for automatically optimizing a Hadoop configuration, given a representative generated data set. There will be a defined optimal result scoring based on the configuration parameters fed to the Hadoop cluster, that will be compared to my algorithms automatic configuration. Relevant scoring metrics are speed of algorithm compared to manual setup or other frameworks, and naturally the relevancy and completeness of data collected.
		\section{Most relevant previous findings}
		\section{Why is this worthwhile}
		During my previous research the motivation for all the papers surveyed was mostly the same. \textbf{First and foremost, it was well acknowledged that Hadoop clusters show very suboptimal performance with out-of-the-box settings. Secondly, it was shown that finding optimal parameters for a Hadoop cluster is very time consuming and hard. As organizations often run with a lack of resources, time and domain-specific engineers, this is a field ripe for improvement.}
		\section{How far will this advance the field?}
		Hopefully this will provide a fully functional, open source light weight framework allowing companies to easily deploy Hadoop Clusters without worrying about tailoring the solution or suboptimal performance. If the task proves to be too big, this will lay the foundation for further work to make a de facto solution. Or something.
		\section{Structure of the report}
		Add comments about every chapter here.
	\chapter{Related literature and theoretical focus}
	\chapter{Presentation of domain where technology is used}
	\chapter{Method}
	\chapter{Results}
	\chapter{Discussion}
	\chapter{Conclusion}
	\begin{thebibliography}{1}
		
		\bibitem{bigdata3}
		Bollier, D., \& Firestone, C. M. (2010). \emph{The promise and peril of big data (p. 1).} Washington, DC: Aspen Institute, Communications and Society Program.
	\end{thebibliography}
\end{document}